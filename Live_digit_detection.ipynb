{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        channels_conv1 = 1\n",
    "        \n",
    "        self.Conv_Layers = nn.Sequential(\n",
    "            nn.Conv2d(channels_conv1,10,kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=3),\n",
    "            nn.Dropout2d(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.Linear_Layers = nn.Sequential(\n",
    "            nn.Linear(500,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10),\n",
    "            nn.ReLU(),\n",
    "            nn.LogSoftmax(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Conv_Layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.Linear_Layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_config():\n",
    "\n",
    "    config = {\n",
    "          'batch_size_train':64,\n",
    "          'batch_size_test':1000,\n",
    "          'log_interval':40,      #How often to dislay (batch) loss during training\n",
    "          'epochs': 20,           #Number of epochs\n",
    "          'learning_rate': 0.0001,\n",
    "         }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, epoch, data_loader, optimizer, is_training, config):\n",
    "    if is_training==True: \n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0 \n",
    "    correct = 0 \n",
    "    labels_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "    for batch_idx, (features,target) in enumerate(data_loader):\n",
    "        \n",
    "        if not is_training:\n",
    "            with torch.no_grad():\n",
    "                prediction = model(features)\n",
    "                loss = F.nll_loss(prediction,target)\n",
    "                total_loss = total_loss + loss.detach().cpu().numpy()  \n",
    "            \n",
    "        elif is_training:\n",
    "            prediction = model(features)\n",
    "            loss = F.nll_loss(prediction,target)\n",
    "            total_loss = total_loss + loss.detach().cpu().numpy() \n",
    "\n",
    "            #Update gradients based on loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        # Compute the correct classification\n",
    "        predicted_label = np.zeros(prediction.shape)\n",
    "        predicted_label = np.argmax(prediction.detach().numpy(), axis=-1)\n",
    "    loss_avg = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(predicted_label, target)\n",
    "\n",
    "    print(f'Epoch={epoch} | loss = {total_loss/(batch_idx+1)} | accuracy = {accuracy}')\n",
    "    \n",
    "    return loss_avg, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(model,features):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(features)\n",
    "        predicted_label = np.zeros(prediction.shape)\n",
    "        predicted_label = np.argmax(prediction.detach().numpy(), axis=-1)\n",
    "    pred = F.softmax(prediction)\n",
    "    pred = pred.detach().numpy()\n",
    "    return predicted_label, np.max(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_image(image, size):\n",
    "    U, s, V = np.linalg.svd(image,full_matrices=False)\n",
    "    op1 = np.dot(np.diag(s[:size]),V[:size,:])\n",
    "    compressed = np.dot(U[:,:size], op1)\n",
    "    return compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def draw_on_gui(event, x, y, flags, params): #params\n",
    "    global draw, window\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        draw=True\n",
    "        cv2.circle( window, (x,y), cv2.getTrackbarPos(\"Brush Size\", title), (255,255,255), -1 )\n",
    "        \n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if draw:\n",
    "            cv2.circle( window, (x,y), cv2.getTrackbarPos(\"Brush Size\", title), (255,255,255), -1 )\n",
    "    \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        draw=False\n",
    "        cv2.circle( window, (x,y), cv2.getTrackbarPos(\"Brush Size\", title), (255,255,255), -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_window(*args):\n",
    "    cv2.rectangle(window, (0,0), (839,839), (0,0,0),-1)\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_loop(title, window,model):\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        cv2.imshow(title, window)\n",
    "        key = cv2.waitKey(1)\n",
    "        #print(draw)\n",
    "        if key==ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "        cur = cv2.resize(window, dsize=(28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "        cur = cur/255\n",
    "        \n",
    "        data = torch.tensor(cur)\n",
    "        data = data.double()\n",
    "        data.unsqueeze_(0).unsqueeze_(0)\n",
    "        pred, prob = run_prediction(model.double(),data)\n",
    "        \n",
    "        if count%100 == 0:\n",
    "            print(pred, prob)\n",
    "        \n",
    "        if count == 1000:\n",
    "            count = 0\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_batches(dataloader,k):\n",
    "    c = 1\n",
    "    for i, (image, target) in enumerate(dataloader):\n",
    "        plt.subplot(1, k, c)\n",
    "        plt.axis('off')\n",
    "        img = image[0,0,:,:]\n",
    "        plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        if c==k:\n",
    "            break\n",
    "        c+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0 | loss = 0.8719135157620983 | accuracy = 0.90625\n",
      "Epoch=0 | loss = 0.274331858754158 | accuracy = 0.937\n",
      "Epoch=1 | loss = 0.30603417793094223 | accuracy = 0.96875\n",
      "Epoch=1 | loss = 0.19327524453401565 | accuracy = 0.943\n",
      "Epoch=2 | loss = 0.23835919530931185 | accuracy = 0.9375\n",
      "Epoch=2 | loss = 0.15859853178262712 | accuracy = 0.943\n",
      "Epoch=3 | loss = 0.19974441211948643 | accuracy = 0.9375\n",
      "Epoch=3 | loss = 0.1269892029464245 | accuracy = 0.97\n",
      "Epoch=4 | loss = 0.17661763408751502 | accuracy = 0.96875\n",
      "Epoch=4 | loss = 0.10976491197943687 | accuracy = 0.973\n",
      "Epoch=5 | loss = 0.16206388694565815 | accuracy = 0.90625\n",
      "Epoch=5 | loss = 0.10216489359736443 | accuracy = 0.976\n",
      "Epoch=6 | loss = 0.15070726938331241 | accuracy = 0.9375\n",
      "Epoch=6 | loss = 0.09296474307775497 | accuracy = 0.976\n",
      "Epoch=7 | loss = 0.14099297164154967 | accuracy = 0.96875\n",
      "Epoch=7 | loss = 0.08550019338726997 | accuracy = 0.975\n",
      "Epoch=8 | loss = 0.13369282200606838 | accuracy = 0.96875\n",
      "Epoch=8 | loss = 0.08175333887338639 | accuracy = 0.976\n",
      "Epoch=9 | loss = 0.128464542190308 | accuracy = 0.90625\n",
      "Epoch=9 | loss = 0.0786026269197464 | accuracy = 0.977\n",
      "Epoch=10 | loss = 0.12435857909145767 | accuracy = 0.90625\n",
      "Epoch=10 | loss = 0.07460872605443 | accuracy = 0.978\n",
      "Epoch=11 | loss = 0.1201260795892238 | accuracy = 0.90625\n",
      "Epoch=11 | loss = 0.07058324217796326 | accuracy = 0.98\n",
      "Epoch=12 | loss = 0.11895906264339683 | accuracy = 1.0\n",
      "Epoch=12 | loss = 0.07281509898602963 | accuracy = 0.983\n",
      "Epoch=13 | loss = 0.11388865344401107 | accuracy = 0.9375\n",
      "Epoch=13 | loss = 0.0678611345589161 | accuracy = 0.978\n",
      "Epoch=14 | loss = 0.11281681868400592 | accuracy = 0.96875\n",
      "Epoch=14 | loss = 0.06568779647350312 | accuracy = 0.978\n",
      "Epoch=15 | loss = 0.11038216278910129 | accuracy = 1.0\n",
      "Epoch=15 | loss = 0.066261026263237 | accuracy = 0.98\n",
      "Epoch=16 | loss = 0.10841170946028886 | accuracy = 0.96875\n",
      "Epoch=16 | loss = 0.06392301879823208 | accuracy = 0.983\n",
      "Epoch=17 | loss = 0.10631588578863597 | accuracy = 0.96875\n",
      "Epoch=17 | loss = 0.06063559614121914 | accuracy = 0.98\n",
      "Epoch=18 | loss = 0.10437240813181663 | accuracy = 0.875\n",
      "Epoch=18 | loss = 0.06054048575460911 | accuracy = 0.988\n",
      "Epoch=19 | loss = 0.10443928668787802 | accuracy = 0.96875\n",
      "Epoch=19 | loss = 0.06050371192395687 | accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "cconf = cnn_config()\n",
    "\n",
    "DL_train = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])), batch_size=cconf['batch_size_train'], shuffle=True)\n",
    "\n",
    "DL_test = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=cconf['batch_size_test'], shuffle=True)\n",
    "\n",
    "CNNmodel = CNNClassifier()\n",
    "optimizer = optim.Adam(CNNmodel.parameters(), lr=0.0001, weight_decay=0.01)#001)\n",
    "\n",
    "loss_train = np.zeros(shape=cconf['epochs'])\n",
    "acc_train = np.zeros(shape=cconf['epochs'])\n",
    "loss_test = np.zeros(shape=cconf['epochs'])\n",
    "acc_test = np.zeros(shape=cconf['epochs'])\n",
    "\n",
    "for epoch in range(cconf['epochs']):\n",
    "    loss_train[epoch],acc_train[epoch] = run_epoch(CNNmodel,epoch,DL_train,optimizer,True,cconf)\n",
    "    loss_test[epoch],acc_test[epoch] = run_epoch(CNNmodel,epoch,DL_test,optimizer,False,cconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images_from_batches(DL_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.11169279114911733\n",
      "[1] 0.11169279114911733\n",
      "[1] 0.11169279114911733\n",
      "[1] 0.11169279114911733\n",
      "[1] 0.11169279114911733\n",
      "[7] 0.38341753973179005\n",
      "[7] 0.7396335865956949\n",
      "[7] 0.7805701699977601\n",
      "[7] 0.7805701699977601\n",
      "[7] 0.7805701699977601\n",
      "[7] 0.7805701699977601\n",
      "[1] 0.11169279114911733\n",
      "[7] 0.14553674507108322\n",
      "[4] 0.4081658361185622\n",
      "[4] 0.7683701504837994\n",
      "[4] 0.7343809427552082\n",
      "[4] 0.7343809427552082\n",
      "[4] 0.7343809427552082\n",
      "[4] 0.7343809427552082\n",
      "[1] 0.11169279114911733\n",
      "[2] 0.17788731554202206\n",
      "[5] 0.3912382020865006\n",
      "[5] 0.7400580145916927\n",
      "[5] 0.7400580145916927\n",
      "[5] 0.7400580145916927\n",
      "[5] 0.7400580145916927\n",
      "[5] 0.7400580145916927\n",
      "[5] 0.7400580145916927\n",
      "[1] 0.11169279114911733\n",
      "[1] 0.7395728376457978\n",
      "[1] 0.7236740806629026\n",
      "[1] 0.7236740806629026\n",
      "[1] 0.7236740806629026\n",
      "[1] 0.7236740806629026\n",
      "[1] 0.11169279114911733\n",
      "[7] 0.3147987977349301\n",
      "[5] 0.41331409599681873\n",
      "[8] 0.658968903708815\n",
      "[8] 0.658968903708815\n",
      "[8] 0.658968903708815\n"
     ]
    }
   ],
   "source": [
    "title = \"Neural Network Guesser\"\n",
    "draw = False\n",
    "mat = np.zeros((840,840),np.uint8)#np.ones((840,840),np.uint8)*255\n",
    "\n",
    "cv2.namedWindow(title)\n",
    "\n",
    "window = cv2.rectangle(mat, (0,0), (839,839), (0,0,0),-1)\n",
    "cv2.createTrackbar(\"Brush Size\", title, 33, 50, nothing)\n",
    "cv2.createButton(\"Clear\", clear_window)\n",
    "cv2.setMouseCallback(title, draw_on_gui)\n",
    "update_loop(title, window, CNNmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181970f4a20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cur = cv2.resize(window, dsize=(28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(cur, cmap=plt.cm.gray_r, interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo: Make True GUI buttons, make a numberdisplay that updates instead of a print, \n",
    "#make a function to save image with corrsponding targetlabel, make it web\n",
    "#clean all code, make orderly filesystem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
